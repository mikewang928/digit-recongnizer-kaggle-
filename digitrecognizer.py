# -*- coding: utf-8 -*-
"""DigitRecognizer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lALLC5Y1P-6uDlCHoJ8KzbPexbJv2Or3
"""

#step 0: loading data into the colab

#Opt 1: Import data stroage from google
from google.colab import drive 
drive.mount('/content/drive')

#Opt 2: drag data from your laptop to the 'Files' bar on the top left

# Step 1: Initialize the running environment
from __future__ import print_function
import keras
import gc
import tensorflow as tf
import torch
import pandas as pd
from keras.callbacks import EarlyStopping
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
import pandas as pd
import numpy as np
from scipy.stats import mode
import matplotlib.pyplot as plt
from keras.applications.vgg16 import VGG16
from keras.applications.densenet import DenseNet201
from keras_preprocessing.image import ImageDataGenerator
from keras import backend as K

# Init Parameters
num_classes = 10                    #0-9
valid_portion = 0.03 
model_name = 'DenseNet201'

# Step 2: Load Training data to memory

# Loading data from whatever path
# Here I load from the google drive I mounted
path = '/content/drive/My Drive/DigRec/'

train = pd.read_csv(path+'train.csv')

y_train = train["label"].to_numpy() # the colomn of "label" to numpy config as y_train
x_train = train.drop(labels = ["label"],axis = 1).to_numpy() # the rest of the data to numpy config as x_train
"""
print(x_train): 
[[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
"""
# Rememeber memory and disk are valuable in Colab
# Always collect the garbage
del train # grabage collection: delete train as it is useless for now 

#Change training data to tensor type 
#astype():casting the element to certian datatype; torch.tensor.numpy: change back the tensor to a numpy; reshape(-1,28,28,1): four dimensional tensor for convolution purposes
x_train = torch.Tensor(x_train).reshape(-1,28,28,1).numpy().astype('float32')/255 #reshape(-1=inferred dimension, width, height, #of channels)
#print(y_train): [1 0 1 ... 7 6 9]
y_train = keras.utils.to_categorical(y_train, num_classes) 
"""
print(y_train): 
[[0. 1. 0. ... 0. 0. 0.]
 [1. 0. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 1. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 1.]]
"""

#split train and validation data.
valid_range = (int)(len(x_train) * (1-valid_portion)) # valid_portion=0.03; valid_range=40740; len(x_train)=42000
x_valid = x_train[valid_range:] #x_train dimension：(40740,28,28,1); x_valid dimension: (1260,28,28,1)
x_train = x_train[:valid_range] #x_train dimension：(40740,28,28,1)
y_valid = y_train[valid_range:] #y_train dimension：(40740,10); y_valid dimension：(1260,10)
y_train = y_train[:valid_range] #y_train dimension：(40740,10)

#Confirm the data type
print('x_train shape:', x_train.shape)
print('x_valid shape:', x_valid.shape)
print('y_train shape:', y_train.shape)
print('y_valid shape:', y_valid.shape)

#collect garbage
gc.collect()

# Step 3: Time to build the model

#OPT1------
#Initialize the model

#Initialize the component

#des = DenseNet201(include_top=True, weights=None,input_shape=(28,28,1), classes=10)
#trans = keras.layers.Conv2D(filters=3,kernel_size=5,padding='same')


#conv2d: https://www.tensorflow.org/api_docs/python/tf/nn/conv2d
#conv2d.filter: https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/
"""A “Kernel” refers to a 2D array of weights. The term “filter” is for 3D structures of multiple kernels stacked together. 
For a 2D filter, filter is same as kernel. But for a 3D filter and most convolutions in deep learning, a filter is a collection of kernels.
Each kernel is unique, emphasizing different aspects of the input channel."""
conv2d_1 =  Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', 
                 activation ='relu', input_shape = (28,28,1))
conv2d_2 =  Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', 
                 activation ='relu', input_shape = (28,28,1))
pool_1 =    MaxPooling2D(pool_size=(2,2))
drop_1 =    Dropout(0.25)

conv2d_3 =  Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', 
                 activation ='relu')
conv2d_4 =  Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', 
                 activation ='relu')
pool_2 =    MaxPooling2D(pool_size=(2,2),strides = (2,2))
drop_2 =    Dropout(0.25)

drop_3 =    Dropout(0.5)



#Add components to model
model = Sequential()

model.add(conv2d_1)
model.add(conv2d_2)
model.add(pool_1)
model.add(drop_1)

model.add(conv2d_3)
model.add(conv2d_4)
model.add(pool_2)
model.add(drop_2)

model.add(Flatten())
model.add(drop_3)
model.add(Dense(256,activation='relu'))
model.add(Dense(10, activation = "softmax"))

"""Also called Softmax Loss. It is a Softmax activation plus a Cross-Entropy loss. 
If we use this loss, we will train a CNN to output a probability over the
classes for each image. It is used for multi-class classification."""

model.compile(loss='categorical_crossentropy',
       optimizer=keras.optimizers.Adam(lr=1e-4),
       metrics=['accuracy'])

#OPT2------
#Load the model
saved_model_name = model_name+'_804'
model = keras.models.load_model('/content/'+saved_model_name)
#Change the learning rate
#Usually goes like 1e-4 5e-5 5e-6 5e-7end
K.set_value(model.optimizer.lr, 5e-6)
print(K.get_value(model.optimizer.lr))

### TRAINING START! ###
#Usually we go 5 models and then adjust the learning rate
#Epochs: #of iterations for the entire data to go through the network 
batch_size = (int)(0.05*len(x_train))
for i in range(50):
  print('Trail: ',i)
  history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1, verbose=1)
  score = model.evaluate(x_valid, y_valid, verbose=1)
  print('Test loss:', score[0])
  print('Test accuracy:', score[1])
  model.save(model_name+'_{}'.format(int(score[1]*1000))) #

del history
gc.collect()

x_test = pd.read_csv(path+'test.csv').to_numpy()
x_test = torch.Tensor(x_test).reshape(-1,28,28,1).numpy().astype('float32')/255 

pred = model.predict(x_test,verbose=1)
pred = np.argmax(pred,axis=1)

pred_csv = pd.DataFrame(data = pred, columns=['Label'],index = [i for i in range(1,len(pred)+1)])
pred_csv = pred_csv.rename_axis('ImageId')
pred_csv.to_csv(r'result.csv')